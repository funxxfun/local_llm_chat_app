# ふみの相棒 〜Locl LLM Chat〜 について

これはローカルLLMを学習するための教材用のチャットアプリです

## 参考にした教材

UDEMY：[ローカルLLMを使ってRAGが導入された本格的なチャットボットを作ろう！ローカルLLM実行ツールであるOllamaとPythonを使ってローカル環境にいくら実行しても無料のAI環境を作ろう！](https://www.udemy.com/share/10dS9F3@9Q29aQpZVKej_KDdIrQKqsGHrirD2S-SZ3mfRI89jReu2sJOOFlIG2Qx74fJ-eV-mw==/)

1. 環境構築：Ollamaをインストールし、Llamaモデルをローカル実行

2. Python実装：ターミナルからPythonコードへの移行

3. UI開発：StreamlitでチャットボットWebアプリを作成

4. RAG導入：Embeddingsモデルでドキュメント検索を組み込み、回答精度を強化


# 開発環境

macOS：Sequoia 15.4.1

Llama：3.1:8b

OpenAI：1.99.3

Python：13.0

Streamlit：1.40.1
